{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plots\n",
    "plots.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions to think about:\n",
    "\n",
    "**1. Try and gauge the scope of the database. How many types of animals? How many types of variables? What are the measurements? Are there variables that are required for each data point? Try to explain in a programmatic way.**\n",
    "\n",
    "While exploring the database, a very vital question came to me: Is is possible to aggregate ALL of the data from MorphoSource? Probably. Although the sheer amount of data avaliable would most likely burden my computer's memory too much, and unless there's a way that I'm not aware of, I would have to individually add to cart/download the files one-by-one (which would be very tedious and perhaps result in missed datasets). \n",
    "\n",
    "The scope of the data really traverses many areas, and there is most likely over 10,000 specimens (and growing). And there's not only data about the actual specimen/organism itself, but also its body parts (teeth).\n",
    "\n",
    "But in the context of the database that I'm working with currently, which is \"Project: oVert: UW - CT Scan all Fishes\" by/from Cornell University's Museum of Vertebrates, the scope of the data is basically all the known fish species in the world (or at least the team is trying to achieve this). As of right now, there are around 8000 recorded and scanned fish from their dataset, categorized/labeled with around 20 variables. But majority of the column labels (from the provided google doc) pertains mainly to the type of scanner, dates, times, and other information not related to the actual fish. But the dataset does provide the general categorizations (i.e. Genus, Species). There are also extra links for a few of the fishes that provide additional information. See [here](https://docs.google.com/spreadsheets/d/1TUqJJNPFdAEjncQXJ8D6iX0ootl5EfiNNHEE9kPgQpE/edit?ts=5702a468#gid=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3565"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = Table().read_table(\"Fish_scans.csv\") #Reading in the file \n",
    "\n",
    "#Grouped by unique species\n",
    "Species_grouped = file.group(\"Species\")\n",
    "\n",
    "#the number of rows in the table correspond to the number of unique species recorded\n",
    "#After skimming over the data, I filtered out all the ones that had unspecified species names\n",
    "#Note: I may have missed some due to the different standards in indentifying unknown species\n",
    "#This is another thing to account for when looking at this dataset (unstandardized naming inputs)\n",
    "filter_count = Species_grouped.where(\"Species\", are.not_equal_to(\"nan\")).where(\"Species\", are.not_equal_to(\"not sure\")).where(\"Species\", are.not_equal_to(\"unsure\")).where(\"Species\", are.not_equal_to(\"tbd\"))\n",
    "\n",
    "#number of unique fish species\n",
    "filter_count.num_rows   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Family_grouped = file.group(\"family\")\n",
    "\n",
    "#filtered out unknowns\n",
    "filtered_family = Family_grouped.where(\"family\", are.not_equal_to(\"??\")).where(\"family\", are.not_equal_to(\"nan\"))\n",
    "# Family_grouped.show() #used this to look through/skim dataset since it's in alphabetical order here\n",
    "\n",
    "#unique families\n",
    "filtered_family.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1473"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Genus_grouped = file.group(\"Genus\")\n",
    "\n",
    "filtered_genus = Genus_grouped.where(\"Genus\", are.not_equal_to(\"#VALUE!\")).where(\"Genus\", are.not_equal_to(\"nan\"))\n",
    "filtered_anomaly = filtered_genus.where(\"Genus\", are.not_equal_to(\"21\")) \n",
    "filtered_anomaly.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Data Quality: Are there ways to access the quality of this data? For example, if there are geographic points, does it make sense that whales were found in the middle of Iowa? What are some assumptions that you have to make about this data? Are there clear documentation on the standards that are required to input data into this database?**\n",
    "\n",
    "Honestly, I would say that improvements to the quality of the data can be made, especially since there's a good amount of \"N/A\" and/or \"None\" data inputs (as briefly analyzed in the previous post). Also, I would prefer if they provided some sort of key as to what the column labels are referring to when categorizing the data. I would also like to know where the team gathered these fishes (at least in the google doc--But if you look at the \"spec. image\" column, you will find a photo of the actual fish that was scanned), because I do notice that the whereabouts and other specifics about the fish can be found when clicking into the individual fish scan, but this can be tedious if I want to compare certain fishes with others. But from the context of their description, I will assume that their primary goal is to simply scan all the fishes and not actually provide any sort of analysis with the data. Though their collection can be helpful for research in areas pertaining to how many types of fish are in a certain Genus/etc. \n",
    "\n",
    "**3. Completeness: requires that a particular column, element or class of data is populated and does not feature null values or values in place of nulls (e.g. N/As).**\n",
    "\n",
    "Not fully complete! See below for brief analysis (but all mainly less than 1% unknown from vast dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Category</th> <th>Unknown percentage</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>Family  </td> <td>0.510204          </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Species </td> <td>0.112076          </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Genus   </td> <td>0.203252          </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Category | Unknown percentage\n",
       "Family   | 0.510204\n",
       "Species  | 0.112076\n",
       "Genus    | 0.203252"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentages unknown from data set for respecitive category \n",
    "unk1 = (Family_grouped.num_rows - filtered_family.num_rows) / Family_grouped.num_rows * 100\n",
    "unk2 = (Species_grouped.num_rows - filter_count.num_rows) / Species_grouped.num_rows * 100 \n",
    "unk3 = (Genus_grouped.num_rows - filtered_anomaly.num_rows) / Genus_grouped.num_rows * 100 \n",
    "briefUnk = Table().with_column(\"Category\", make_array(\"Family\", \"Species\", \"Genus\"),\n",
    "                                \"Unknown percentage\", make_array(unk1, unk2, unk3))\n",
    "briefUnk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Accuracy: the hardest dimension to test for as this often requires some kind of manual checking by a Subject Matter Expert (SME).**\n",
    "\n",
    "When photographing the fishes/collecting the scans, I noticed that they did use a sort of symbol, either an \"X\" or some other shape. This was may likely be used to create a standard size comparision for each fish and to maintain a sense of consistency/accuracy for future reproduction. However, without a key/description, I can't be absolutely certain what each column label is representing. Moreover, some of the recorded data is missing this input value, which again points to the rather lack of completeness of data on some parts.\n",
    "\n",
    "**5. What are the variables that are most interesting to you? At some point you will need to refine the scope of your project. You likely cannot explore ALL the data. Are their questions about the that are particularly interesting to you? Questions can either be about the quality of the data or of biological significance.**\n",
    "\n",
    "I would love to figure out where each species of fish is located at (and add to the data) since the provided data is not available, and see where, geographically, majority of a specific species or genus are most commonly found. I realize that most (if not all) of the fish data have been imported from iDigBio, so I could look into that and figure out/gather geographical data that corresponds to the data provided from MorphoSource. And perhaps in response to the quality of the data, I maybe find out information and propose what some of the missing data is? \n",
    "\n",
    "Another thing that I would really love to learn how to create visualizations of the data. So it might be interesting to create a visual or map geographically where the fish species are found at, with larger clusters on the more populated aeas of the map. I want to see how else I can visualize the data as well. \n",
    "\n",
    "On a side note, I'm actually curious as to when majority of the information was recorded/scanned. That is, were most of the fishes scanned during 2018, or earlier dates. . .or was the data collection consistent throughout the years.\n",
    "\n",
    "**6. Reiterate what skills you particullarly interested in learning. Do you see a clear path from this database to level up on those skills?**\n",
    "\n",
    "I'm particularly interested in learning different visualization techniques. From this database, I'm hoping I can aggregate the data and try out different representations of the (limited) but provided data. Though, because there is a limited amount of data pertaining to the fishes themselves, I may have to look for another dataset to continue my research. But regardless, I do want to play around with matplotlib (especially how to use/import their basemap so that I could potentiall create a symbol map for a particular fish species) and d3js (which is a javascript library used to manipulate documents and create visualizations).\n",
    "\n",
    "Another thing, I might want to try out is to perhaps create a k-NN classfier (or related tools) to identify/fill in the missing blanks in the data. But this might be hard since there's not much data about the physical appearance of the fish itself, so it'll be hard to collect features to test out this mechanism. \n",
    "\n",
    "**7. If you are having a hard time understanding how to handle the data, is there a clear path for learning how? Is there something that could be done to the data on the database side that would make your life easier when using this data? Do you wish it was in json over XML? Do you wish that there was a tool in Python that would connect to the database? Did you find the documentation incredibly hard to follow? What are some things you googled that helped you? What are the things you googled that had no answer but wish there was?**\n",
    "\n",
    "I would say that cleaning up some of the data would definitely be very helpful in seeing the different types of data and relationships. I did also have to look up some of the scanner data since I wasn't familiar with the types of tools that they used to record the data. And, I did mention this previously, but a key/documentation would be nice to have so that I know exactly what each column label is referring to. And I actually wish there was more information about the fish besides it's genus/family/etc. For example, info on the weight, color, size, etc might be helpful. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
